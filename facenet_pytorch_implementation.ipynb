{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42087d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, extract_face\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2147313",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin =20\n",
    "image_size = 160\n",
    "\n",
    "# Load face detector\n",
    "mtcnn = MTCNN(keep_all=False, select_largest=False, post_process=False,\n",
    "              device=device,margin=margin, image_size=image_size,thresholds=[0.7, 0.7, 0.7])\n",
    "\n",
    "# Load facial recognition model\n",
    "resnet = InceptionResnetV1(pretrained='casia-webface', device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c09ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = np.asarray(image)\n",
    "    # detect faces in the image\n",
    "    face_array = mtcnn(pixels)\n",
    "    if face_array==None:\n",
    "        return None\n",
    "    return face_array.permute(1,2,0).int().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71297cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 529)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open(\"/home/server/Shahid/Datasets/Bollywood_celeb_dataset_100_classes/bollywood_celeb_faces_0/Aamir_Khan/5.jpg\")\n",
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eddf52d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 74 sample for class: Bobby_Deol\n",
      "loaded 83 sample for class: Akshaye_Khanna\n",
      "loaded 114 sample for class: Ameesha_Patel\n",
      "loaded 121 sample for class: Bipasha_Basu\n",
      "loaded 97 sample for class: Anil_Kapoor\n",
      "loaded 110 sample for class: Ajay_Devgn\n",
      "loaded 97 sample for class: Arjun_Rampal\n",
      "loaded 144 sample for class: Ileana_D+У+З+ЦCruz\n",
      "loaded 110 sample for class: Aftab_Shivdasani\n",
      "loaded 128 sample for class: Huma_Qureshi\n",
      "loaded 96 sample for class: Bhumi_Pednekar\n",
      "loaded 157 sample for class: Anushka_Sharma\n",
      "loaded 144 sample for class: Anushka_Shetty\n",
      "loaded 113 sample for class: Ayushmann_Khurrana\n",
      "loaded 134 sample for class: Amitabh_Bachchan\n",
      "loaded 147 sample for class: Asin\n",
      "loaded 122 sample for class: Amy_Jackson\n",
      "loaded 75 sample for class: Abhay_Deol\n",
      "loaded 121 sample for class: Amrita_Rao\n",
      "loaded 77 sample for class: Govinda\n",
      "loaded 146 sample for class: Disha_Patani\n",
      "loaded 156 sample for class: Aishwarya_Rai\n",
      "loaded 103 sample for class: Abhishek_Bachchan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 105 sample for class: Arshad_Warsi\n",
      "loaded 111 sample for class: Arjun_Kapoor\n",
      "loaded 133 sample for class: Aamir_Khan\n",
      "loaded 95 sample for class: Emraan_Hashmi\n",
      "loaded 79 sample for class: Farhan_Akhtar\n",
      "loaded 193 sample for class: Deepika_Padukone\n",
      "loaded 110 sample for class: Esha_Gupta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 115 sample for class: Hrithik_Roshan\n",
      "loaded 164 sample for class: Alia_Bhatt\n",
      "loaded 122 sample for class: Akshay_Kumar\n",
      "(3896, 160, 160, 3) (3896,)\n",
      "loaded 126 sample for class: Parineeti_Chopra\n",
      "loaded 124 sample for class: Karisma_Kapoor\n",
      "loaded 134 sample for class: Kriti_Kharbanda\n",
      "loaded 156 sample for class: Katrina_Kaif\n",
      "loaded 143 sample for class: Madhuri_Dixit\n",
      "loaded 115 sample for class: Juhi_Chawla\n",
      "loaded 137 sample for class: Kajol\n",
      "loaded 130 sample for class: Kangana_Ranaut\n",
      "loaded 118 sample for class: Ranbir_Kapoor\n",
      "loaded 136 sample for class: Priyanka_Chopra\n",
      "loaded 150 sample for class: Pooja_Hegde\n",
      "loaded 131 sample for class: Kiara_Advani\n",
      "loaded 138 sample for class: Prabhas\n",
      "loaded 133 sample for class: Preity_Zinta\n",
      "loaded 119 sample for class: John_Abraham\n",
      "loaded 159 sample for class: Jacqueline_Fernandez\n",
      "loaded 117 sample for class: Irrfan_Khan\n",
      "loaded 123 sample for class: Nargis_Fakhri\n",
      "loaded 86 sample for class: Lara_Dutta\n",
      "loaded 82 sample for class: Paresh_Rawal\n",
      "loaded 138 sample for class: Kareena_Kapoor\n",
      "loaded 107 sample for class: Mrunal_Thakur\n",
      "loaded 93 sample for class: Manoj_Bajpayee\n",
      "loaded 152 sample for class: Kriti_Sanon\n",
      "loaded 82 sample for class: Naseeruddin_Shah\n",
      "loaded 76 sample for class: Kunal_Khemu\n",
      "loaded 95 sample for class: R_Madhavan\n",
      "loaded 123 sample for class: Kartik_Aaryan\n",
      "loaded 163 sample for class: Kajal_Aggarwal\n",
      "loaded 81 sample for class: Nana_Patekar\n",
      "loaded 98 sample for class: Rajkummar_Rao\n",
      "loaded 110 sample for class: Nushrat_Bharucha\n",
      "loaded 115 sample for class: Prachi_Desai\n",
      "(3990, 160, 160, 3) (3990,)\n",
      "loaded 160 sample for class: Yami_Gautam\n",
      "loaded 131 sample for class: Sonam_Kapoor\n",
      "loaded 55 sample for class: Shreyas_Talpade\n",
      "loaded 100 sample for class: Sanjay_Dutt\n",
      "loaded 124 sample for class: Sonakshi_Sinha\n",
      "loaded 137 sample for class: Varun_Dhawan\n",
      "loaded 100 sample for class: Sushant_Singh_Rajput\n",
      "loaded 127 sample for class: Tiger_Shroff\n",
      "loaded 128 sample for class: Rani_Mukerji\n",
      "loaded 62 sample for class: Tusshar_Kapoor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/PIL/TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 144 sample for class: Vidya_Balan\n",
      "loaded 100 sample for class: Vicky_Kaushal\n",
      "loaded 117 sample for class: Richa_Chadda\n",
      "loaded 99 sample for class: Saif_Ali_Khan\n",
      "loaded 129 sample for class: Shruti_Haasan\n",
      "loaded 114 sample for class: Shraddha_Kapoor\n",
      "loaded 140 sample for class: Shilpa_Shetty\n",
      "loaded 80 sample for class: Vivek_Oberoi\n",
      "loaded 139 sample for class: Zareen_Khan\n",
      "loaded 152 sample for class: Vaani_Kapoor\n",
      "loaded 111 sample for class: Sara_Ali_Khan\n",
      "loaded 118 sample for class: Shah_Rukh_Khan\n",
      "loaded 81 sample for class: Sunny_Deol\n",
      "loaded 99 sample for class: Sidharth_Malhotra\n",
      "loaded 82 sample for class: Riteish_Deshmukh\n",
      "loaded 116 sample for class: Tabu\n",
      "loaded 124 sample for class: Ranveer_Singh\n",
      "loaded 176 sample for class: Tamannaah_Bhatia\n",
      "loaded 139 sample for class: Taapsee_Pannu\n",
      "loaded 109 sample for class: Randeep_Hooda\n",
      "loaded 141 sample for class: Shahid_Kapoor\n",
      "loaded 72 sample for class: Uday_Chopra\n",
      "loaded 71 sample for class: Suniel_Shetty\n",
      "loaded 140 sample for class: Salman_Khan\n",
      "(3917, 160, 160, 3) (3917,)\n"
     ]
    }
   ],
   "source": [
    "def load_face(dir):\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in os.listdir(dir):\n",
    "        path = dir + '/'+ filename\n",
    "        if (\".jpg\" not in filename) and (\".png\" not in filename):\n",
    "            continue\n",
    "        face = extract_face(path)\n",
    "        if face is None:\n",
    "            continue\n",
    "        faces.append(face) \n",
    "    return faces\n",
    "\n",
    "def load_dataset(dir):\n",
    "    # list for faces and labels\n",
    "    X, y = list(), list()\n",
    "    for subdir in os.listdir(dir):\n",
    "        path =dir +'/'+subdir\n",
    "        faces = load_face(path)\n",
    "        labels = [subdir for i in range(len(faces))]\n",
    "        print(\"loaded %d sample for class: %s\" % (len(faces),subdir) ) # print progress\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return np.asarray(X), np.asarray(y)\n",
    "\n",
    "\n",
    "# load train dataset\n",
    "trainX1, trainy1 = load_dataset('/home/server/Shahid/Datasets/Bollywood_celeb_dataset_100_classes/bollywood_celeb_faces_0')\n",
    "print(trainX1.shape, trainy1.shape)\n",
    "\n",
    "trainX2, trainy2 = load_dataset('/home/server/Shahid/Datasets/Bollywood_celeb_dataset_100_classes/bollywood_celeb_faces_1')\n",
    "print(trainX2.shape, trainy2.shape)\n",
    "\n",
    "trainX3, trainy3 = load_dataset('/home/server/Shahid/Datasets/Bollywood_celeb_dataset_100_classes/bollywood_celeb_faces2')\n",
    "print(trainX3.shape, trainy3.shape)\n",
    "\n",
    "# save and compress the dataset for further use\n",
    "#np.savez_compressed('5-celebrity-faces-dataset.npz', trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acc9e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=np.concatenate((trainX1,trainX2,trainX3), axis=0)\n",
    "trainy=np.concatenate((trainy1,trainy2,trainy3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ecf06ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11803,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6420e1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39msavez_compressed(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m100_Bollywood_celebrity_faces_dataset.npz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtrainX\u001b[49m, trainy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "np.savez_compressed('100_Bollywood_celebrity_faces_dataset.npz',trainX,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37684bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  (11803, 160, 160, 3) (11803,)\n"
     ]
    }
   ],
   "source": [
    "# load the face dataset\n",
    "data = np.load('100_Bollywood_celebrity_faces_dataset.npz')\n",
    "trainX, trainy = data['arr_0'], data['arr_1']\n",
    "print('Loaded: ', trainX.shape, trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8c456ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11803,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016970b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8604\\2732514964.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2441\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2443\u001b[1;33m     return list(\n\u001b[0m\u001b[0;32m   2444\u001b[0m         chain.from_iterable(\n\u001b[0;32m   2445\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2443\u001b[0m     return list(\n\u001b[0;32m   2444\u001b[0m         chain.from_iterable(\n\u001b[1;32m-> 2445\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2446\u001b[0m         )\n\u001b[0;32m   2447\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX,testX,trainy,testy=train_test_split(trainX,trainy, test_size=0.33, random_state=42,stratify=trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c588dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "tf_img = lambda i: ToTensor()(i).unsqueeze(0).float()\n",
    "embeddings = lambda input: resnet(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc41922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each face in the train set into embedding\n",
    "emdTrainX = list()\n",
    "for face in trainX:\n",
    "    #mean, std = face.mean(), face.std()\n",
    "    #face = (face-mean)/std\n",
    "    face=face/255\n",
    "    t = tf_img(face).to(device)\n",
    "    emd = embeddings(t).squeeze().cpu().tolist()\n",
    "    emdTrainX.append(emd)\n",
    "    #print(len(emd))\n",
    "    \n",
    "emdTrainX = np.asarray(emdTrainX)\n",
    "print(emdTrainX.shape)\n",
    "\n",
    "# convert each face in the test set into embedding\n",
    "emdTestX = list()\n",
    "for face in testX:\n",
    "    mean, std = face.mean(), face.std()\n",
    "    #face = (face-mean)/std\n",
    "    face=face/255\n",
    "    t = tf_img(face).to(device)\n",
    "    emd = embeddings(t).squeeze().cpu().tolist()\n",
    "    emdTestX.append(emd)\n",
    "emdTestX = np.asarray(emdTestX)\n",
    "print(emdTestX.shape)\n",
    "\n",
    "# save arrays to one file in compressed format\n",
    "np.savez_compressed('100-Bollywood_celebrity-faces-embeddings.npz', emdTrainX, trainy, emdTestX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c948b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(\"100-Bollywood_celebrity-faces-embeddings.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af1ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdTrainX, trainy, emdTestX, testy=data[\"arr_0\"],data[\"arr_1\"],data[\"arr_2\"],data[\"arr_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14199f67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"Dataset: train=%d, test=%d\" % (emdTrainX.shape[0], emdTestX.shape[0]))\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer()\n",
    "emdTrainX_norm=emdTrainX#no effect of normalizer\n",
    "emdTestX_norm=emdTestX\n",
    "#emdTrainX_norm = in_encoder.transform(emdTrainX)\n",
    "#emdTestX_norm = in_encoder.transform(emdTestX)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy_enc = out_encoder.transform(trainy)\n",
    "testy_enc = out_encoder.transform(testy)\n",
    "# fit model\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(emdTrainX_norm, trainy_enc)\n",
    "# predict\n",
    "yhat_train = model.predict(emdTrainX_norm)\n",
    "yhat_test = model.predict(emdTestX_norm)\n",
    "# score\n",
    "score_train = accuracy_score(trainy_enc, yhat_train)\n",
    "score_test = accuracy_score(testy_enc, yhat_test)\n",
    "# summarize\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2890cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "# select a random face from test set\n",
    "selection = choice([i for i in range(testX.shape[0])])\n",
    "random_face = testX[selection]\n",
    "random_face_emd = emdTestX_norm[selection]\n",
    "random_face_class = testy_enc[selection]\n",
    "random_face_name = out_encoder.inverse_transform([random_face_class])\n",
    "\n",
    "# prediction for the face\n",
    "samples = np.expand_dims(random_face_emd, axis=0)\n",
    "yhat_class = model.predict(samples)\n",
    "yhat_prob = model.predict_proba(samples)\n",
    "# get name\n",
    "class_index = yhat_class[0]\n",
    "class_probability = yhat_prob[0,class_index] * 100\n",
    "predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "all_names = out_encoder.inverse_transform(list(np.unique(trainy_enc)))\n",
    "#print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
    "#print('Predicted: \\n%s \\n%s' % (all_names, yhat_prob[0]*100))\n",
    "print('Expected: %s' % random_face_name[0])\n",
    "print(\"predicted:\",predict_names[0])\n",
    "# plot face\n",
    "plt.imshow(random_face)\n",
    "title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc26d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3819719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55bd15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
